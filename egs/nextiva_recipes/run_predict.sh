#!/usr/bin/env bash

# This script predicts a *single* transcription from a *single* novel audio.

# This script will assume that the necessary items are in `nextiva_recipes/{exp, mfcc}` unless
# updated.

# TODO streamline - remove all unnecessary steps (such as logging etc)


# ARGUMENTS
### REQUIRED INPUT
# -a <path> = full path to audio file to be transcribed
# -g <path> = full path to existing `graph`, default = `exp/triphones/graph/HCLG.fst`
# -l <path> = full path to the lexicon lookup file, default = `exp/triphones/graph/words.txt`
# -i <path> = full path to lexicon alignment file, default = `data/lang/phones/align_lexicon.int`
# -o <path> = full path to the model (`.mdl`) file, default = `exp/triphones_2_aligned/final.mdl`
# -c <path> = full path to mfcc-config file
# -q <string> = non-vanilla hyperparameters to `decode_for_predict.sh`, in the form "--beam 20"
# -r <string> = non-vanilla hyperparameters to `compute_cmvn_stats.sh`, in the form "--fake-dims 13:14"

### OPTIONAL INPUT
# -j <int> = number of threads to use when generating mfcc's and decoding, default = `2`
# -u [no argument] = if present, audio will remain *unsegmented*

### REQUIRED OUTPUT
# -d <path> = directory to house files generated by this process, default = `exp/triphones/decode_test_dir`

### OPTIONAL OUTPUT
# -m <path> = directory to house output mfccs from this process if are to be kept after decoding

### OPTIONAL TEMPORARY
# -t <path> = full path to temp folder, default = `/tmp/kaldi_decode/

### OPTIONAL HYPERPARAMETER
# -w <int> = lattice weight to use during scoring, default = `10`

# default variables
num_processors=2
segmented=true
temp=/tmp/kaldi_decode/
graph=${PATH_TO_KALDI}/egs/nextiva_recipes/exp/triphones/graph/HCLG.fst
words=${PATH_TO_KALDI}/egs/nextiva_recipes/exp/triphones/graph/words.txt
words_align=${PATH_TO_KALDI}/egs/nextiva_recipes/data/lang/phones/align_lexicon.int
model=${PATH_TO_KALDI}/egs/nextiva_recipes/exp/triphones_2_aligned/final.mdl
decode_test_dir=${PATH_TO_KALDI}/egs/nextiva_recipes/exp/triphones/decode_test_dir/
mfcc_conf=
weight=10
decode_hyperparameters=
cmvn_hyperparameters=

# place new mfcc's into temp folder to be deleted after process
mfcc_dir=${temp}mfcc/
mkdir -p ${mfcc_dir}

while getopts "j:a:t:g:l:i:o:d:m:w:uc:q:r:" opt; do
    case ${opt} in
        j)
            num_processors=${OPTARG}
            ;;
        a)
            audio_path=${OPTARG}
            ;;
        t)
            temp=${OPTARG}/
            ;;
        g)
            graph=${OPTARG}
            ;;
        l)
            words=${OPTARG}
            ;;
        i)
            words_align=${OPTARG}
            ;;
        o)
            model=${OPTARG}
            ;;
        d)
            decode_test_dir=${OPTARG}/
            ;;
        m)
            mfcc_dir=${OPTARG}/
            mkdir -p ${mfcc_dir}
            ;;
        w)
            weight=${OPTARG}
            ;;
        c)
            mfcc_conf=${OPTARG}
            ;;
        u)
            segmented=false
            ;;
        q)
            decode_hyperparameters=${OPTARG}
            ;;
        r)
            cmvn_hyperparameters=${OPTARG}
            ;;
        \?)
            echo "Wrong flags"
            exit 1
            ;;
    esac
done

# make sure folders don't already exist
rm -rf ${temp}
rm -rf ${decode_test_dir}

# create necessary directories
mkdir -p ${temp}log ${temp}data

# build utt_id
utt_id=$(basename ${audio_path} .wav)

# build wav.scp
echo ${utt_id} ${audio_path} > ${temp}data/wav.scp

if [ "${segmented}" = true ]; then
# if audio is to be *segmented*
    # run diarization
    # TODO how to limit to 2 speakers? `--cMinimumOfCluster` isn't working
    java -Xmx1g -jar ${PATH_TO_KALDI}/tools/nextiva_tools/acoustic_pre/LIUM_SpkDiarization-8.4.1.jar \
        --fInputMask=${audio_path} \
        --sOutputMask=${temp}data/segments_raw.seg \
        --cMinimumOfCluster=2 \
        --doCEClustering ${audio_path}
    # format transcripts file
    python ${PATH_TO_KALDI}/tools/nextiva_tools/acoustic_pre/LIUM_seg_to_kaldi_seg.py \
        ${temp}data/segments_raw.seg \
        ${temp}data/segments \
        True
    # sort segments file
    LC_ALL=C sort -i ${temp}data/segments -o ${temp}data/segments
    # build utt2spk
    cat ${temp}data/segments | awk '{printf("%s %s\n", $1, $1);}' > ${temp}data/utt2spk
else
# if audio is to remain *unsegmented*
    # build utt2spk
    echo ${utt_id} ${utt_id} > ${temp}data/utt2spk
fi

# build spk2utt from utt2spk
${PATH_TO_KALDI}/egs/nextiva_recipes/utils/utt2spk_to_spk2utt.pl <${temp}data/utt2spk >${temp}data/spk2utt

if [ "${segmented}" = true ]; then
# if audio is to be *segmented*
    # make mfccs
        # requires only one thread so that splitting doesn't occur
        # outputs files called `raw_mfcc_data.1.{ark,scp}`
    ${PATH_TO_KALDI}/egs/nextiva_recipes/steps/make_mfcc.sh \
            --nj ${num_processors} \
            --mfcc-config ${mfcc_conf} \
            ${temp}data \
            ${temp}log \
            ${mfcc_dir} \
            || (printf "\n####\n#### ERROR: make_mfcc.sh \n####\n\n" && exit 1);
else
# if audio is to remain *unsegmented*
    # make mfccs
        # requires only one thread so that splitting doesn't occur
        # outputs files called `raw_mfcc_data.1.{ark,scp}`
    ${PATH_TO_KALDI}/egs/nextiva_recipes/steps/make_mfcc.sh \
            --nj 1 \
            --mfcc-config ${mfcc_conf} \
            ${temp}data \
            ${temp}log \
            ${mfcc_dir} \
            || (printf "\n####\n#### ERROR: make_mfcc.sh \n####\n\n" && exit 1);
fi

# computes cmnv stats
    # outputs files called `cvmn_data.{ark,scp}`
${PATH_TO_KALDI}/egs/nextiva_recipes/steps/compute_cmvn_stats.sh \
    ${cmvn_hyperparameters} \
    ${temp}data \
    ${temp}log \
    ${mfcc_dir} \
    || (printf "\n####\n#### ERROR: compute_cmvn_stats.sh \n####\n\n" && exit 1);

#Print timestamp in HH:MM:SS (24 hour format)
printf "Timestamp in HH:MM:SS (24 hour format)\n";
date +%T
printf "\n"

# decode
${PATH_TO_KALDI}/egs/nextiva_recipes/steps/decode_for_predict.sh \
    ${decode_hyperparameters} \
    --num_threads ${num_processors} \
    --words ${words} \
    --graph ${graph} \
    --model ${model} \
    ${temp}data \
    ${decode_test_dir} \
    || (printf "\n####\n#### ERROR: decode_for_predict.sh \n####\n\n" && exit 1);


# identify lattice weights to use
weight_lower=$(expr ${weight} - 1)
weight_upper=$(expr ${weight} + 1)

# output transcription
${PATH_TO_KALDI}/egs/nextiva_recipes/local/score_no_wer.sh \
    --min_lmwt ${weight} \
    --max_lmwt ${weight} \
    --words ${words} \
    --words_align ${words_align} \
    --model ${model} \
    ${temp}\
    ${decode_test_dir} |\
    cut -d " " -f2- \
    || (printf "\n####\n#### ERROR: score_no_wer.sh \n####\n\n" && exit 1);

# print .json output to STDOUT
python ${PATH_TO_KALDI}/tools/nextiva_tools/transcription/create_utterance_json.py \
    ${words} \
    ${decode_test_dir}sausage.sau \
    ${decode_test_dir}timestamps.ts

# remove temp
rm -rf ${temp}
